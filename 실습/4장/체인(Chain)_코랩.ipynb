{
 "cells": [
  {
   "cell_type": "code",
   "id": "011d21cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "011d21cc",
    "outputId": "2ce9b3c6-7300-4e5c-c783-9e058de38e54"
   },
   "source": [
    "!pip install langchain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b349242b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b349242b",
    "outputId": "4b8f8f3e-1573-49c0-f927-c8c6faceb248"
   },
   "source": [
    "!pip install openai"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain_community"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOqSs9fgHvYh",
    "outputId": "0365711c-c80f-4d9c-83e4-6113fae78e89"
   },
   "id": "GOqSs9fgHvYh",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9beac4bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "9beac4bc",
    "outputId": "bd5f5fc8-9d9a-4d93-8fe7-1124ce6769ea"
   },
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk\" #openai 키 입력\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정\n",
    "                 model_name='gpt-4',  # 모델명\n",
    "                )\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=[\"country\"],\n",
    "  template= \"{country}의 수도는 어디야?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt) #프롬프트와 모델을 체인으로 연결\n",
    "chain.run(\"대한민국\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0ba88e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0ba88e2",
    "outputId": "dadf55f1-7091-46a8-83e5-4f09e6ad10ac"
   },
   "source": [
    "#프롬프트1 정의\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['sentence'],\n",
    "    template=\"다음 문장을 한글로 번역하세요.\\n\\n{sentence}\"\n",
    ")\n",
    "#번역(체인1)에 대한 모델\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1, output_key=\"translation\")\n",
    "\n",
    "#프롬프트2 정의\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"다음 문장을 한 문장으로 요약하세요.\\n\\n{translation}\"\n",
    ")\n",
    "#요약(체인2)에 대한 모델\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2, output_key=\"summary\")\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "all_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=['sentence'],\n",
    "    output_variables=['translation','summary'],\n",
    ")\n",
    "sentence=\"\"\"\n",
    "One limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). You can combat this by giving LLMs access to the specific external data.\n",
    "For this, you first need to load the external data with a document loader. LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.\n",
    "\"\"\"\n",
    "all_chain(sentence)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "766bbb8d",
   "metadata": {
    "id": "766bbb8d"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_f",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
