{
 "cells": [
  {
   "cell_type": "code",
   "id": "8891e3f7",
   "metadata": {},
   "source": [
    "!pip install unstructured"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fa3dc87",
   "metadata": {},
   "source": [
    "!pip install chromadb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e55467e4",
   "metadata": {},
   "source": [
    "!pip install openai"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "406288de-6386-4a5e-b3e5-5f7524790a8d",
   "metadata": {},
   "source": [
    "!pip install langchain-openai"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1be69cf2",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "documents = TextLoader(\"d:/data/AI.txt\").load()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "124a3fe4",
   "metadata": {},
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서를 청크로 분할\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "# docs 변수에 분할 문서를 저장\n",
    "docs = split_docs(documents)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6434e36c",
   "metadata": {},
   "source": [
    "#OpenAI의 임베딩 모델 사용\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "api_key=\"sk\"\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "\n",
    "# Chromdb에 벡터 저장, 저장 장소는 d:/data\n",
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(docs, embeddings, persist_directory=\"d:/data\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ea8ff78",
   "metadata": {},
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = \"gpt-3.5-turbo\"  #GPT-3.5-turbo 모델 사용\n",
    "llm = ChatOpenAI(model_name=model_name, api_key=api_key)\n",
    "\n",
    "# Q&A 체인을 사용하여 쿼리에 대한 답변 얻기\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=True)\n",
    "\n",
    "# 쿼리를 작성하고 유사성 검색을 수행하여 답변을 생성,따라서 txt에 있는 내용을 질의해야 합니다\n",
    "query = \"AI란?\"\n",
    "matching_docs = db.similarity_search(query)\n",
    "answer =  chain.run(input_documents=matching_docs, question=query)\n",
    "answer\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27a686a4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
